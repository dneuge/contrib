#!/usr/bin/env python3
"""
=encoding utf8

=head1 NAME

podman_ - Podman wildcard-plugin to monitor a L<Podman|https://podman.io> host.

This wildcard plugin provides series C<containers>, C<images>, C<status>,
C<volumes>, C<cpu>, C<memory> and C<network> as separate graphs. It also
supports a C<multi> suffix that provides all of those as a multigraph.

=head1 INSTALLATION

  - Copy this plugin in your munin plugins directory
  - Install Python3 
  - Check your systemd munin-node unit file (see dedicated section below) 

=over 2

If you want all the graphs as a multigraph, create a single multi symlink.

    ln -s /usr/share/munin/plugins/podman_ /etc/munin/plugins/podman_multi

Or choose a subset of those you want.

    ln -s /usr/share/munin/plugins/podman_ /etc/munin/plugins/podman_containers
    ln -s /usr/share/munin/plugins/podman_ /etc/munin/plugins/podman_cpu
    ln -s /usr/share/munin/plugins/podman_ /etc/munin/plugins/podman_images
    ln -s /usr/share/munin/plugins/podman_ /etc/munin/plugins/podman_memory
    ln -s /usr/share/munin/plugins/podman_ /etc/munin/plugins/podman_network
    ln -s /usr/share/munin/plugins/podman_ /etc/munin/plugins/podman_status
    ln -s /usr/share/munin/plugins/podman_ /etc/munin/plugins/podman_volumes

=back

After the installation you need to restart your munin-node:

=over 2

    systemctl restart munin-node

=back

=head1 CONFIGURATION

For this plugin to be able to access all podman instances it needs to be run as root.
To do so you need to create a file named podman placed in the
directory /etc/munin/plugin-conf.d/ with the following config:

You can use the EXCLUDE_CONTAINER_NAME environment variable to specify a regular expression
which if matched will exclude the matching containers from the memory, cpu and network graphs.

For example

 env.EXCLUDE_CONTAINER_NAME runner

would exclude all containers with the word "runner" in the name.

=over 2

    [podman_*]
    user root
    env.EXCLUDE_CONTAINER_NAME regexp

=back

=head1 SYSTEMD TROUBLESHOOTING AND KNOWN ISSUES

=head2 Podman users need to have an API socket

Podman uses systemd extensively and spawns sockets dynamically for the duration of a user login (aka "serverless").
As a result, no information will be available about Podman namespaces for users who are neither logged in nor have
any containers running at the time of Munin data collection.

=head2 Sandbox prevents API socket access/discovery

The default munin-node unit file of your Linux distribution may have been configured to sandbox C</run>
using C<ProtectHome> or similar options. Thus, even if a Podman socket exists, the monitoring plugin may not be
able to access it.

C<ProtectHome=true> hides sockets of users other than the one used to run C<munin-node> in systemd. Running plugins
as specific users (including C<root>) in Munin plugin configurations does not help in that case, you also have to
edit the systemd unit file to open up the sandbox (even C<root> is not allowed to see other users' C</run> directories).

To do so, run C<systemctl edit munin-node.service> (or however your unit file is called) and add override options
to the C<Service> section; either:

=over 2

1. Disable home protection completely - but be aware of the consequences before doing so.

   [Service]
   ProtectHome=false

2. If you know all users you want to monitor containers for and the sockets are always available you could list
   them manually in your unit file. However, this will probably fail munin-node startup if the paths to be bound
   do not exist and you may need to add further service dependencies. This may break your whole Munin monitoring
   if just one of the required Podman sockets is unavailable and thus may not be preferable. At best this should
   only be done when monitoring always-logged-in system users, not regular users as they are not logged in at
   system startup and/or will eventually log out again.

   [Service]
   ProtectHome=tmpfs
   BindPaths=/run/user/1000/podman/ /run/user/1001/podman/

=back

Remember to reload unit files and restart the service after you made any changes, then check if retrieval works
as expected:

  systemctl daemon-reload
  systemctl restart munin-node
  systemctl status munin-node
  # ... also monitor munin log and graph output

=head1 AUTHORS

This section has been reverse-engineered from git logs. Prefix indicates if the changes
were contributed to docker_ original script or podman_ fork.

  [podman_] Daniel Neugebauer <dneuge@energiequant.de>: fork to podman_, initial contribution of Podman library
  [docker_] Codimp <contact@lithio.fr>: original rewrite
  [docker_] Rowan Wookey <admin@rwky.net>: performance improvement
  [docker_] Olivier Mehani <shtrom@ssji.net>: Network support, ClientWrapper, general cleanup, multigraph

=head1 LICENSE

This plugin has been forked from docker/docker_ plugin on 20 March 2022. The original code did not
specify any license and thus is believed to have been distributed under GPL2 as that is the default license
stated in Munin contrib README.

In order to interface with Podman/libpod without requiring additional external dependencies to be installed,
some helper functions & classes had to be written. Those are distributed under the much more compatible MIT license
(relevant code is surrounded by START..END marker comments below) although they have been incorporated to this
presumably GPLv2-licensed file. This is in accordance to the MIT license which allows sublicensing. Any changes
made to the MIT licensed parts should however be made unter MIT terms to allow those improvements to be reused
in non-GPL code (not limited to Munin plugins) as well.

=head1 MAGIC MARKERS

 #%# family=auto
 #%# capabilities=autoconf suggest multigraph

=cut
"""

### START OF MIT-LICENSED CODE
## As access to Podman/libpod API and HTTP-over-Unix-sockets is of more general use and not restricted to
## just munin-contrib plugins this section is to be seen as an independently written, yet incorporated
## piece of code. It has not been split to a library (yet) to make it easier to distribute this plugin
## without having to rely on externally installed dependencies.
##
## Inclusion of this section to GPLv2 licensed code shall not taint independent (re)use, distribution and
## further development of this section's code under the terms of MIT license.
##
##
## This section (until the END OF... marker comment) can be used freely according to the terms of
## the MIT license: (the explanations provided up until here do *not* need to be reproduced on copies)
##
## Copyright 2022 Daniel Neugebauer
##
## Permission is hereby granted, free of charge, to any person obtaining a copy of this software and
## associated documentation files (the "Software"), to deal in the Software without restriction,
## including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense,
## and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so,
## subject to the following conditions:
##
## The above copyright notice and this permission notice shall be included in all copies or substantial
## portions of the Software.
##
## THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT
## LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN
## NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY,
## WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE
## SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
##
from datetime import datetime, timezone
import json
import os
import pwd
import re
import socket
import stat
import time
import urllib.parse

CLIENT_API_VERSION = b'v1.40'
BUFFER_SIZE = 65536

## ultra-basic "HTTP via UNIX socket" implementation for communication with libpod
def connect_unix_socket(socket_path):
    s = socket.socket(socket.AF_UNIX, socket.SOCK_STREAM)
    s.connect(socket_path)
    return s

def extract_http_header_fields(lines):
    http_header_fields = {}
    
    # line-folding is not supported but is obsolete in RFC and should not be used by Podman API
    for line in lines:
        tmp = line.split(':', 1)
        if len(tmp) < 2:
            continue
        http_header_fields[tmp[0].lower()] = tmp[1].strip()

    return http_header_fields

def get(s, endpoint, extra_headers=''):
    url = b'/' + CLIENT_API_VERSION + b'/' + endpoint.encode('ASCII').lstrip(b'/')
    http_request_header  = b'GET ' + url + b' HTTP/1.1\r\n'
    http_request_header += b'Host: d\r\n'
    http_request_header += b'Connection: keep-alive\r\n'
    http_request_header += extra_headers.rstrip('\r\n').encode('ASCII') + b'\r\n'
    http_request_header += b'\r\n'
    s.sendall(http_request_header)

    total_data = bytearray()
    while True:
        this_data = s.recv(BUFFER_SIZE)
        if len(this_data) == 0:
            raise RuntimeError('no data received')
        
        total_data += this_data
        if total_data.find(b'\r\n') < 0:
            continue
        
        http_sections = total_data.split(b'\r\n\r\n', maxsplit=1)
        http_header = http_sections[0].decode('ASCII').split('\r\n')
        http_body = http_sections[1] if len(http_sections) > 1 else None
        
        tmp = http_header[0].split(' ', maxsplit=2)
        http_status = {
            'protocol': tmp[0],
            'code': int(tmp[1]) if len(tmp) > 1 else None,
            'message': tmp[2] if len(tmp) > 2 else None
        }
        
        http_header_fields = extract_http_header_fields(http_header[1:]) if len(http_header) > 1 else {}
        
        if http_body is None:
            continue

        if 'transfer-encoding' in http_header_fields and len(http_header_fields['transfer-encoding']) > 0:
            if http_header_fields['transfer-encoding'] != 'chunked':
                raise RuntimeError('Unsupported Transfer-Encoding: %s' % http_header_fields['transfer-encoding'])
            
            chunks = []
            remainder = http_body
            while len(remainder) > 0:
                tmp = remainder.split(b'\r\n', maxsplit=1)
                if len(tmp) < 2:
                    break
                
                chunk_length = int(tmp[0].decode('ASCII'), 16)
                
                if len(tmp[1]) < chunk_length+2:
                    break

                chunk_data = tmp[1][:chunk_length]
                remainder = tmp[1][chunk_length+2:]
                
                chunks.append((chunk_length, chunk_data))
            
            transfer_complete = len(chunks) > 0 and chunks[-1][0] == 0 and total_data.endswith(b'\r\n\r\n')
            if transfer_complete:
                trailing_headers = chunks[-1][1] + remainder
                trailing_headers_fields = extract_http_header_fields(trailing_headers.decode('ASCII').split('\r\n'))
                http_header_fields.update(trailing_headers_fields)
                
                payload = bytearray()
                for chunk in chunks:
                    if chunk[0] != 0:
                        payload += chunk[1]

                return (http_status, http_header_fields, payload)
        elif 'content-length' in http_header_fields and len(http_header_fields['content-length']) > 0:
            expected_length = int(http_header_fields['content-length'])
            actual_length = len(http_body) if http_body is not None else -1
            
            if actual_length == expected_length:
                return (http_status, http_header_fields, http_body)
            elif actual_length > expected_length:
                raise RuntimeError('Received %d bytes although %d were announced in Content-Length header' % (actual_length, expected_length))
        else:
            raise RuntimeError('HTTP without Content-Length header or chunked transfer cannot be received:\n%s' % total_data.decode('ASCII'))

def get_json(s, endpoint):
    status, header, body = get(s, endpoint, 'Accept: application/json')
    charset = 'utf-8'

    if status['code'] != 200:
        raise RuntimeError('unhandled status code %d' % status['code'])
    
    if 'content-type' in header:
        # podman sometimes indicates plaintext although responding with JSON content
        parts = [part.strip() for part in header['content-type'].split(';')]
        if parts[0] not in ['application/json', 'text/plain']:
            raise RuntimeError('unhandled content-type %s' % header['content-type'])
        
        if len(parts) > 1:
            for part in parts[1:]:
                tmp = part.split('=')
                if tmp[0].strip().lower() == 'charset':
                    charset = tmp[1].strip().lower()
    
    json_str = body.decode(charset)
    return json.loads(json_str)

## Podman/libpod API
class ContainerStatistics:
    def __init__(self, json, is_root):
        self.retrieved_nanoseconds = json['SystemNano']
        self.container_id = json['ContainerID']
        self.runtime_totalized_cpu_nanoseconds = json['CPUNano']
        self.memory_used = json['MemUsage']
        self.num_processes = json['PIDs']
        
        # IO counters are only expected to provide data if podman runs under root user,
        # otherwise counters will be stuck at 0. Just in case we get non-zero values
        # we should use them nevertheless.
        self.network_in = json['NetInput']
        self.network_out = json['NetOutput']
        self.network_stats = is_root or self.network_in != 0 or self.network_out != 0
        
        # a container without IO cannot exist, so in case we encounter 0 as root that
        # statistic is simply unavailable and should be disabled for root user as well
        self.block_in = json['BlockInput']
        self.block_out = json['BlockOutput']
        self.block_stats = self.block_in != 0 or self.block_out != 0
    
    def get_retrieved_nanoseconds(self):
        return self.retrieved_nanoseconds
    
    def get_runtime_totalized_cpu_nanoseconds(self):
        return self.runtime_totalized_cpu_nanoseconds
    
    def get_memory_used(self):
        return self.memory_used
    
    def has_network_stats(self):
        return self.network_stats
    
    def get_network_from_container(self):
        return self.network_in if self.network_stats else None
    
    def get_network_to_container(self):
        return self.network_out if self.network_stats else None
    
    def has_block_stats(self):
        return self.block_stats
    
    def get_block_bytes_read(self):
        return self.block_in if self.block_stats else None
    
    def get_block_bytes_written(self):
        return self.block_out if self.block_stats else None

    def get_num_processes(self):
        return self.num_processes

re_iso_datetime = re.compile('^(\d{4}-\d{2}-\d{2}T\d{2}:\d{2}:\d{2}\.\d{6})\d*([+\-]\d{2}:\d{2})$')
def parse_iso_datetime(s):
    # datetime.fromisoformat does not tolerate higher precision than microseconds
    m = re_iso_datetime.match(s)
    if m is not None:
        s = m.group(1) + m.group(2)
    
    return datetime.fromisoformat(s)

class Container:
    def __init__(self, uid, json):
        self.uid = uid
        self.container_id = json['Id']
        self.created = parse_iso_datetime(json['Created'])
        self.image = json['ImageName'] if 'ImageName' in json else json['Image']
        self.name = json['Name'] if 'Name' in json else json['Names'][0]
        
        if isinstance(json['State'], str):
            self.status = json['State']
            self.health_status = None
        else:
            state = json['State']
            self.status = state['Status']
            self.health_status = state.get('Healthcheck', {}).get('Status', None)
            if self.health_status == '':
                self.health_status = None
    
    def get_id(self):
        return self.container_id
    
    def get_uid(self):
        return self.uid

    def get_image(self):
        return self.image
    
    def get_name(self):
        return self.name
    
    def get_status(self):
        return self.status
    
    def get_health_status(self):
        return self.health_status
    
    def get_created(self):
        return self.created

class Image:
    def __init__(self, uid, json):
        self.image_id = json['Id']
        self.uid = uid
        self.created = datetime.fromtimestamp(json['Created'], tz=timezone.utc)
        self.digest = tuple(json['Digest'].split(':'))
        self.names = set(json['Names'])
        self.size = json['Size']
        self.tags = set(json['RepoTags'])
    
    def get_id(self):
        return self.image_id
    
    def get_uid(self):
        return self.uid
    
    def get_created(self):
        return self.created
    
    def get_digest(self):
        return self.digest
    
    def get_names(self):
        return self.names.copy()
    
    def get_size(self):
        return self.size
    
    def get_tags(self):
        return self.tags.copy()

class Volume:
    def __init__(self, uid, json):
        self.name = json['Name']
        self.uid = uid
        self.created = parse_iso_datetime(json['CreatedAt'])
        self.labels = json['Labels']
    
    def get_name(self):
        return self.name
    
    def get_uid(self):
        return self.uid
    
    def get_created(self):
        return self.created
    
    def get_labels(self):
        return self.labels.copy()

class PodmanAPI:
    def __init__(self, uid):
        self.uid = uid
        self.is_root = (uid == 0)
        socket_path = '/run/podman/podman.sock' if self.is_root else '/run/user/%d/podman/podman.sock' % (uid)
        self.socket = connect_unix_socket(socket_path)
    
    def __del__(self):
        self.socket.close()
    
    def get_uid(self):
        return self.uid
    
    def containers(self):
        return [Container(self.uid, container_json) for container_json in get_json(self.socket, '/libpod/containers/json?all=true')]
    
    def container(self, container_id):
        return Container(self.uid, get_json(self.socket, '/libpod/containers/%s/json' % container_id))
    
    def images(self, all=True, filter_dangling=None):
        params = {}
        if all:
            params['all'] = 'true'
        
        filters = {}
        if filter_dangling:
            # this looks weird but API actually performs some duplicate unpacking with an intermediate map and everything else gives a 500 error
            filters['dangling'] = {'true': True}
        if len(filters) > 0:
            params['filters'] = json.dumps(filters)

        return [Image(self.uid, i) for i in get_json(self.socket, '/libpod/images/json?'+urllib.parse.urlencode(params, quote_via=urllib.parse.quote))]

    def stats(self):
        json = get_json(self.socket, '/libpod/containers/stats?stream=false')
        return {c['ContainerID']: ContainerStatistics(c, self.is_root) for c in json['Stats']}

    def volumes(self):
        return [Volume(self.uid, v) for v in get_json(self.socket, '/libpod/volumes/json')]

def is_socket(path):
    return stat.S_ISSOCK(os.stat(path).st_mode)

re_only_numbers = re.compile('^\d+$')
def find_accessible_podman_uids():
    uids = set()
    
    root_socket_path = '/run/podman/podman.sock'
    if is_socket(root_socket_path) and os.access(root_socket_path, os.R_OK | os.W_OK):
        uids.add(0)

    user_base_dir = '/run/user/'
    with os.scandir(user_base_dir) as it:
        for entry in it:
            if not entry.is_dir() or re_only_numbers.match(entry.name) is None:
                continue
            
            uid = int(entry.name)
            
            socket_path = '%s%d/podman/podman.sock' % (user_base_dir, uid)
            if is_socket(socket_path) and os.access(socket_path, os.R_OK | os.W_OK):
                uids.add(uid)
            
    return uids
### END OF MIT-LICENSED CODE
### All following code resumes the standard license under which this plugin is being distributed.


from datetime import datetime
import os
import sys
import re
try:
    from functools import cached_property
except ImportError:
    # If cached_property is not available,
    # just use the property decorator, without caching
    # This is for backward compatibility with Python<3.8
    cached_property = property
from multiprocessing import Process, Queue


def sorted_by_creation_date(func):
    def sorted_func(*args, **kwargs):
        return sorted(
            func(*args, **kwargs),
            key=(
                lambda x: x.get_created()
            )
        )
    return sorted_func


def clean_fieldname(text):
    if text == "root":
        # "root" is a magic (forbidden) word
        return "_root"
    else:
        return re.sub(r"(^[^A-Za-z_]|[^A-Za-z0-9_])", "_", text)

def full_container_name(c):
    # TODO: document changed format for exclude parameter
    # TODO: add option to use username instead of uid
    return '%d/%s' % (c.get_uid(), c.get_name())

class ClientWrapper:
    """
    A single-instance wrapper for multiple Podman sockets, to centralise some parsing logic,
    and support caching.

    In addition, when the exclude_re parameter is not None,
    any container which name is matched by the RE will not be excluded from reports.
    """
    apis = None
    exclude = None

    def __init__(self, apis, exclude_re=None):
        self.apis = {api.get_uid(): api for api in apis}
        if exclude_re:
            self.exclude = re.compile(exclude_re)
        
        self.cpu_persistence_path = '/tmp/munin-podman-cpustats-%s' % (get_wildcard())

    @property
    def api(self):
        return self.client.api

    @cached_property
    @sorted_by_creation_date
    def all_containers(self):
        containers = []
        for api in self.apis.values():
            containers += [
                c for c in api.containers()
                if not self.exclude or not self.exclude.search(full_container_name(c))
            ]
        return containers

    def inspect_container(self, container):
        api = self.apis[container.get_uid()]
        return api.container(container.get_id())

    @cached_property
    @sorted_by_creation_date
    def intermediate_images(self):
        wanted_ids = {(i.get_uid(), i.get_id()) for i in self.all_images}.difference(
            {(i.get_uid(), i.get_id()) for i in self.images}
            .difference(
                {(i.get_uid(), i.get_id()) for i in self.dangling_images}
            )
        )
        return [image for image in self.all_images if (image.get_uid(), image.get_id()) in wanted_ids]

    def load_cpu_stats(self):
        stats = {}
        if os.path.exists(self.cpu_persistence_path):
            try:
                with open(self.cpu_persistence_path, 'r') as fh:
                    stats = json.load(fh)
            except Exception as e:
                print('Loading CPU stats failed: %s' % e, file=sys.stderr)
        return stats
    
    def save_cpu_stats(self, cpu_stats):
        with os.fdopen(os.open(self.cpu_persistence_path, os.O_WRONLY | os.O_CREAT | os.O_TRUNC, 0o600), 'w') as fh:
            json.dump(cpu_stats, fh)

    @cached_property
    def stats(self):
        out = {}
        
        containers_by_id = {c.get_id(): c for c in self.all_containers}
        
        previous_cpu_stats = self.load_cpu_stats()
        current_cpu_stats = {}
        
        for api in self.apis.values():
            for container_id, stats in api.stats().items():
                current_retrieved_nano = stats.get_retrieved_nanoseconds()
                current_cpu_nano = stats.get_runtime_totalized_cpu_nanoseconds()
                current_cpu_stats[container_id] = (current_retrieved_nano, current_cpu_nano)
                previous_retrieved_nano = current_retrieved_nano
                previous_cpu_nano = current_cpu_nano
                
                if container_id in previous_cpu_stats:
                    previous = previous_cpu_stats[container_id]
                    previous_retrieved_nano = previous[0]
                    previous_cpu_nano = previous[1]
                
                if container_id in containers_by_id:
                    container = containers_by_id[container_id]
                    out[container] = {
                        'cpu_total_usage': current_cpu_nano,
                        'cpu_retrieved': current_retrieved_nano,
                        'precpu_total_usage': previous_cpu_nano,
                        'precpu_retrieved': previous_retrieved_nano,
                        'memory_usage': stats.get_memory_used(),
                        'tx_bytes': stats.get_network_from_container(),
                        'rx_bytes': stats.get_network_to_container(),
                    }
        
        # only overwrite cpu statistics if cpu graph was supposed to be generated by this run
        if get_wildcard() in ['cpu', 'multi']:
            self.save_cpu_stats(current_cpu_stats)

        return out
    
    @cached_property
    @sorted_by_creation_date
    def all_images(self):
        images = []
        for api in self.apis.values():
            images += api.images()
        return images

    @cached_property
    @sorted_by_creation_date
    def images(self):
        images = []
        for api in self.apis.values():
            images += api.images(all=False)
        
        wanted_ids = {(i.get_uid(), i.get_id()) for i in images}.difference({(i.get_uid(), i.get_id()) for i in self.dangling_images})
        return [image for image in images if (image.get_uid(), image.get_id()) in wanted_ids]

    @cached_property
    @sorted_by_creation_date
    def dangling_images(self):
        images = []
        for api in self.apis.values():
            images += api.images(all=False, filter_dangling=True)
        return images

    @cached_property
    @sorted_by_creation_date
    def volumes(self):
        volumes = []
        for api in self.apis.values():
            volumes += api.volumes()
        return volumes


def container_summary(container, *args):
    summary = full_container_name(container)
    attributes = container_attributes(container, *args)
    if attributes:
        summary += f' ({attributes})'
    return summary


def container_attributes(container, *args):
    attributes = [container.get_image(), container.get_created().isoformat()]
    return ', '.join(attributes + list(args))


def container_fieldname(container):
    return clean_fieldname('u%d_%s' % (container.get_uid(), container.get_name()))

def print_containers_status(client):
    running = []
    unhealthy = []
    paused = []
    created = []
    restarting = []
    removing = []
    exited = []
    dead = []
    for container in client.all_containers:
        status = container.get_status()
        if status == 'running':
            health_status = client.inspect_container(container).get_health_status()
            if health_status is not None and health_status != 'healthy':
                unhealthy.append(container)
            else:
                running.append(container)
        elif status == 'paused':
            paused.append(container)
        elif status in ['created', 'configured']:
            created.append(container)
        elif status == 'restarting':
            restarting.append(container)
        elif status == 'removing':
            removing.append(container)
        elif status == 'exited':
            exited.append(container)
        elif status == 'dead':
            dead.append(container)
    print('running.value', len(running))
    print('running.extinfo', ', '.join(container_summary(c) for c in running))
    print('unhealthy.value', len(unhealthy))
    print('unhealthy.extinfo', ', '.join(container_summary(c) for c in unhealthy))
    print('paused.value', len(paused))
    print('paused.extinfo', ', '.join(container_summary(c) for c in paused))
    print('created.value', len(created))
    print('created.extinfo', ', '.join(container_summary(c) for c in created))
    print('restarting.value', len(restarting))
    print('restarting.extinfo', ', '.join(container_summary(c) for c in restarting))
    print('removing.value', len(removing))
    print('removing.extinfo', ', '.join(container_summary(c) for c in removing))
    print('exited.value', len(exited))
    print('exited.extinfo', ', '.join(container_summary(c) for c in exited))
    print('dead.value', len(dead))
    print('dead.extinfo', ', '.join(container_summary(c) for c in dead))


def short_digest(image):
    return '%s:%.10s' % image.get_digest()


def image_full_id(image):
    return '%d/%s' % (image.get_uid(), short_digest(image))


def image_summary(image):
    attributes = list(sorted(image.get_tags().union(image.get_names())))
    attributes.append(image.get_created().isoformat())
    attributes.append(f"{round(image.get_size()/1024**2, 2)} MiB")
    return f"{image_full_id(image)} ({', '.join(attributes)})"


def print_images_count(client):
    images = client.images
    intermediate = client.intermediate_images
    dangling = client.dangling_images

    print('intermediate_quantity.value', len(intermediate))
    print('intermediate_quantity.extinfo', ', '.join(image_summary(i) for i in intermediate))
    print('images_quantity.value', len(images))
    print('images_quantity.extinfo', ', '.join(image_summary(i) for i in images))
    print('dangling_quantity.value', len(dangling))
    print('dangling_quantity.extinfo', ', '.join(image_summary(i) for i in dangling))


def print_containers_cpu(client):
    for container, stats in client.stats.items():
        cpu_percent = 0.0
        cpu_delta = (float(stats["cpu_total_usage"]) - float(stats["precpu_total_usage"]))
        system_delta = (float(stats["cpu_retrieved"]) - float(stats["precpu_retrieved"]))
        if system_delta > 0.0:
            cpu_percent = cpu_delta / system_delta * 100.0 * os.cpu_count()
        fieldprefix = container_fieldname(container)
        print(fieldprefix + '.value', cpu_percent)
        print(fieldprefix + '.extinfo', container_attributes(container))


def print_containers_memory(client):
    for container, stats in client.stats.items():
        memory_usage = stats['memory_usage']
        extinfo = 'Total memory usage'
        fieldprefix = container_fieldname(container)
        print(fieldprefix + '.value', memory_usage)
        print(fieldprefix + '.extinfo', container_attributes(container, extinfo))


def print_containers_network(client):
    for container, stats in client.stats.items():
        fieldprefix = container_fieldname(container)
        print(fieldprefix + '_up.value', stats['tx_bytes'])
        print(fieldprefix + '_down.value', stats['rx_bytes'])
        print(fieldprefix + '_up.extinfo', container_attributes(container))


def volume_full_id(volume):
    return '%d/%s' % (volume.get_uid(), volume.get_name())


def volume_summary(volume):
    summary = volume_full_id(volume)
    labels = volume.get_labels()
    if len(labels) > 0:
        summary += f" ({', '.join(sorted(labels))})"
    return summary


def status(client, mode):
    if mode == "config":
        print("graph_title Podman status")
        print("graph_vlabel containers")
        print("graph_category virtualization")
        print("graph_total All containers")
        print("running.label RUNNING")
        print("running.draw AREASTACK")
        print("running.info Running containers can be manipulated with "
              "`podman container [attach|kill|logs|pause|restart|stop] <NAME>` or "
              "commands run in them with `podman container exec "
              "[--detach|--interactive,--privileged,--tty] <NAME> <COMMAND>`"
              )
        print("unhealthy.label UNHEALTHY")
        print("unhealthy.draw AREASTACK")
        print("unhealthy.warning 1")
        print("unhealthy.info Unhealthy containers can be restarted with "
              "`podman container restart <NAME>`")
        print("paused.label PAUSED")
        print("paused.draw AREASTACK")
        print("paused.info Paused containers can be resumed with "
              "`podman container unpause <NAME>`")
        print("created.label CREATED")
        print("created.draw AREASTACK")
        print("created.info New containers can be created with "
              "`podman container create --name <NAME> <IMAGE_ID >` or "
              "`podman container run --name <NAME> <IMAGE_ID> <COMMAND>`")
        print("restarting.label RESTARTING")
        print("restarting.draw AREASTACK")
        print("restarting.info Containers can be restarted with "
              "`podman container restart <NAME>`")
        print("removing.label REMOVING")
        print("removing.draw AREASTACK")
        print("removing.info Containers can be removed with "
              "`podman container rm <NAME>`")
        print("exited.label EXITED")
        print("exited.draw AREASTACK")
        print("exited.info Exited containers can be started with "
              "`podman container start [--attach] <NAME>`")
        print("dead.label DEAD")
        print("dead.draw AREASTACK")
        print("dead.warning 1")
        print("dead.info Dead containers can be started with "
              "`podman container start <NAME>`")
    else:
        print_containers_status(client)


def containers(client, mode):
    if mode == "config":
        print("graph_title Podman containers")
        print("graph_vlabel containers")
        print("graph_category virtualization")
        print("containers_quantity.label Containers")
    else:
        print('containers_quantity.value', len(client.all_containers))


def images(client, mode):
    if mode == "config":
        print("graph_title Podman images")
        print("graph_vlabel images")
        print("graph_category virtualization")
        print("graph_total All images")
        print("intermediate_quantity.label Intermediate images")
        print("intermediate_quantity.draw AREASTACK")
        print("intermediate_quantity.info All unused images can be deleted with "
              "`podman image prune --all`")
        print("images_quantity.label Images")
        print("images_quantity.draw AREASTACK")
        print("images_quantity.info Images can be used in containers with "
              "`podman container create --name <NAME> <IMAGE_ID >` or "
              "`podman container run --name <NAME> <IMAGE_ID> <COMMAND>`")
        print("dangling_quantity.label Dangling images")
        print("dangling_quantity.draw AREASTACK")
        print("dangling_quantity.info Dangling images can be deleted with "
              "`podman image prune`"
              "or tagged with `podman image tag <IMAGE_ID> <NAME>`")
        print("dangling_quantity.warning 10")
    else:
        print_images_count(client)


def volumes(client, mode):
    if mode == "config":
        print("graph_title Podman volumes")
        print("graph_vlabel volumes")
        print("graph_category virtualization")
        print("volumes_quantity.label Volumes")
        print("volumes_quantity.draw AREASTACK")
        print("volumes_quantity.info Unused volumes can be deleted with "
              "`podman volume prune`")
    else:
        print('volumes_quantity.value', len(client.volumes))
        print('volumes_quantity.extinfo', ', '.join(volume_summary(v) for v in client.volumes))


def cpu(client, mode):
    if mode == "config":
        graphlimit = str(os.cpu_count() * 100)
        print("graph_title Podman containers CPU usage")
        print("graph_args --base 1000 -r --lower-limit 0 --upper-limit " + graphlimit)
        print("graph_scale no")
        print("graph_period second")
        print("graph_vlabel CPU usage (%)")
        print("graph_category virtualization")
        print("graph_info This graph shows podman container CPU usage.")
        print("graph_total Total CPU usage")
        for container in client.all_containers:
            fieldname = container_fieldname(container)
            print("{}.label {}".format(fieldname, full_container_name(container)))
            print("{}.draw AREASTACK".format(fieldname))
            print("{}.info {}".format(fieldname, container_attributes(container)))
    else:
        print_containers_cpu(client)


def network(client, mode):
    if mode == "config":
        print("graph_title Podman containers network usage")
        print("graph_args --base 1024 -l 0")
        print("graph_vlabel bits in (-) / out (+) per ${graph_period}")
        print("graph_category virtualization")
        print("graph_info This graph shows podman container network usage.")
        print("graph_total Total network usage")
        for container in client.all_containers:
            fieldname = container_fieldname(container)
            print("{}_down.label {}_received".format(fieldname, full_container_name(container)))
            print("{}_down.type DERIVE".format(fieldname))
            print("{}_down.min 0".format(fieldname))
            print("{}_down.graph no".format(fieldname))
            print("{}_down.cdef {}_down,8,*".format(fieldname, fieldname))
            print("{}_up.label {}".format(fieldname, full_container_name(container)))
            print("{}_up.draw LINESTACK1".format(fieldname))
            print("{}_up.type DERIVE".format(fieldname))
            print("{}_up.min 0".format(fieldname))
            print("{}_up.negative {}_down".format(fieldname, fieldname))
            print("{}_up.cdef {}_up,8,*".format(fieldname, fieldname))
            print("{}_up.info {}".format(fieldname, container_attributes(container)))
    else:
        print_containers_network(client)


def memory(client, mode):
    if mode == "config":
        print("graph_title Podman containers memory usage")
        print("graph_args --base 1024 -l 0")
        print("graph_vlabel Bytes")
        print("graph_category virtualization")
        print("graph_info This graph shows podman container memory usage.")
        print("graph_total Total memory usage")
        for container in client.all_containers:
            fieldname = container_fieldname(container)
            print("{}.label {}".format(fieldname, full_container_name(container)))
            print("{}.draw AREASTACK".format(fieldname))
            print("{}.info {}".format(fieldname, container_attributes(container)))
    else:
        print_containers_memory(client)


def get_wildcard():
    return sys.argv[0].split("podman_")[1].split("_")[0]

def main():
    series = [
        'containers',
        'cpu',
        'images',
        'memory',
        'network',
        'status',
        'volumes',
    ]

    try:
        mode = sys.argv[1]
    except IndexError:
        mode = ""
    wildcard = get_wildcard()

    try:
        apis = [PodmanAPI(uid) for uid in find_accessible_podman_uids()]
        
        if len(apis) == 0:
            raise RuntimeError('no accessible Podman sockets found')
        
        if mode == "autoconf":
            print('yes')
            sys.exit(0)
    except Exception as e:
        print(f'no ({e})')
        if mode == "autoconf":
            sys.exit(0)
        sys.exit(1)

    if mode == "suggest":
        # The multigraph covers all other graphs,
        # so we only need to suggest one
        print("multi")
        sys.exit(0)

    client = ClientWrapper(apis,
                           exclude_re=os.getenv('EXCLUDE_CONTAINER_NAME'))

    if wildcard in series:
        # dereference the function name by looking in the globals()
        # this assumes that the function name matches the series name exactly
        # if this were to change, a different approach would be needed,
        # most likely using a Dict of series name string to callable
        globals()[wildcard](client, mode)
    elif wildcard == 'multi':
        for s in series:
            print(f'multigraph podman_{s}')
            # ditto
            globals()[s](client, mode)
    else:
        print(f'unknown series ({wildcard})', file=sys.stderr)
        sys.exit(1)


if __name__ == '__main__':
    main()

# FIXME: check if non-running containers need to be excluded from cpu, memory and network (originally solved by #1209)
# TODO: check all possible container states (status)
# TODO: test if "intermediate" and "dangling" images are shown correctly (first figure out how to produce them, I never had any according to docker_)
# TODO: add option to use username instead of UIDs on labels
# TODO: add option to display UIDs/usernames on labels only in case of name conflicts
# TODO: add option to change sorting to UID and container name (more persistent) instead of creation time
# TODO: add option to override cpustats file location
# TODO: add option to create graphs for specific users (needs adaption of get_wildcard)
